{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 02 - Aprendizagem de Máquina (Parte I)\n",
    "\n",
    "## Pré-processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "filename = 'files/lending_club_loans.csv'\n",
    "df = pd.read_csv(filename, low_memory=False)\n",
    "col_names = df.columns.tolist()\n",
    "print (col_names)\n",
    "print ('Number of attributes: ' + str(len(col_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudo de caso: queremos prever com base nas informações preenchidas pelo cliente que está solicitando um empréstimo se ele será concedido ou não até certo limite. Usaremos dados do Lending Club. \n",
    "\n",
    "Podemos usar o data set para tentar prever empréstimos aceitos com sucesso. Um pedido de empréstimo é bem-sucedido se o valor financiado (funded_amnt) ou o valor financiado pelos investidores (funded_amnt_inv) for próximo ao valor do empréstimo (loan_amnt) solicitado. Nesse sentido, poderíamos colocar um limite no qual a aceitação é baseada como a fórmula: \n",
    "$$\\frac{loan - funded}{loan}\\geq 0.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apagar as colunas que não são úteis para nosso estudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['id', 'member_id', 'grade', 'sub_grade','earliest_cr_line', 'emp_title', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose', 'title', 'zip_code', 'addr_state', 'inq_last_6mths', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'policy_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(drop_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df.columns.tolist()\n",
    "col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checar as features (atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe as features term, emp_length, home_ownership. \n",
    "\n",
    "term e emp_length e emp_length são strings, podemos usar várias estratégias para processá-las: podemos vetorizar os diferentes resultados. Mas observe que existe uma relação de ordem. Nesse caso específico, os valores categóricos podem ser traduzidos diretamente em números que representam essa ordem. Finalmente, house_ownership será vetorizado em tantos recursos quantos forem os valores na variável categórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_term (row):\n",
    "    try:\n",
    "        if row['term']==' 36 months':\n",
    "            d = 1\n",
    "        else:\n",
    "            if row['term']==' 60 months':\n",
    "                d = 2\n",
    "            else:\n",
    "                if np.isnan(row['term']):\n",
    "                    d = None\n",
    "                else:\n",
    "                    print ('WRONG')\n",
    "                    print (row['term'])\n",
    "    except:\n",
    "        print ('EXCEPT')\n",
    "        d = None\n",
    "    return d\n",
    "\n",
    "df['term_clean'] = df.apply (lambda row: clear_term(row),axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['term_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usaremos um dicionário para fazer o mapeamento\n",
    "def clean_emp_length(argument):\n",
    "    switcher = {\n",
    "        '1 year': 1,\n",
    "        '2 years': 2,\n",
    "        '3 years': 3,\n",
    "        '4 years': 4,\n",
    "        '5 years': 5,\n",
    "        '6 years': 6,\n",
    "        '7 years': 7,\n",
    "        '8 years': 8,\n",
    "        '9 years': 9,\n",
    "        '10+ years': 10,\n",
    "        '< 1 year': 0,\n",
    "        'n/a':None,\n",
    "    }\n",
    "    try:\n",
    "        d = switcher[argument['emp_length']]    \n",
    "    except:\n",
    "        d = None\n",
    "    return d\n",
    "\n",
    "df['emp_length_clean'] = df.apply (lambda row: clean_emp_length(row),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "comb_dict = df[['home_ownership']].to_dict(orient='records')\n",
    "vec = DictVectorizer()\n",
    "home = 2*vec.fit_transform(comb_dict).toarray()-1\n",
    "home[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector = pd.DataFrame(home[:,1:])\n",
    "vector_columns = vec.get_feature_names()\n",
    "df_vector.columns = vector_columns[1:]\n",
    "df_vector.index = df.index\n",
    "df_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juntar os dados\n",
    "df = df.join(df_vector)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apagar as colunas processadas\n",
    "df = df.drop(['term','int_rate','emp_length','home_ownership'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem de Máquina Supervisionada - Classificação\n",
    "\n",
    "Aprendizagem de Máquina (AM) é a ciência (ou a arte) de criar sistemas que podem aprender com base em um **conjunto de dados** (treinamento). Uma definição mais generalista descreve AM como \"o campo de estudos que fornece aos computadores a habilidade de aprender sem serem explicitamente programados\".\n",
    "\n",
    "Os sistemas de AM podem ser classificados de acordo com a **quantidade e o tipo de supervisão** que recebem durante o treinamento. Existem três categorias principais: aprendizagem supervisionada, aprendizagem não supervisionada, e aprendizagem semi-supervisionada ou por reforço.\n",
    "\n",
    "Na aprendizagem supervisionada, o algoritmo \"aprende\" ou reconhece padrões com base em exemplos. Na classificação, o algoritmo, também chamado de classificador, reconhece o padrão de um conjunto de dados para prever o valor de um atributo especial denominado classe.\n",
    "\n",
    "Na **aprendizagem supervisionada**, o algoritmo \"aprende\" ou reconhece padrões com base em dados de treinamento. Os dados que você utiliza para treinar o algoritmo incluem um atributo especial que classifica cada instância do conjunto de dados, chamado de classe ou rótulo. Uma atividade típica da aprendizagem supervisionada é a **classificação**. O filtro de spam é um bom exemplo desta técnica: ele é treinado com muitos e-mails de exemplo, e cada um deles possui a sua classe (spam ou não-spam), e o sistema precisa aprender a classificar novos e-mails com base no conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='times')\n",
    "plt.rc('xtick', labelsize=10) \n",
    "plt.rc('ytick', labelsize=10) \n",
    "plt.rc('font', size=12) \n",
    "plt.rc('figure', figsize = (12, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conjunto de dados de exemplo**: continuaremos a usar os dados sobre financiamento bancário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "ofname = open('files/dataset_small.pkl','rb') \n",
    "(x,y) = pickle.load(ofname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checar o volume dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dims = x.shape[1]\n",
    "N = x.shape[0]\n",
    "print 'atributos: ' + str(dims)+', exemplos: '+ str(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos construir um classificador simples**\n",
    "\n",
    "A primeira etapa é o **treinamento**: executar o algoritmo usando o conjunto de dados para que ele \"aprenda\" a reconhecer o padrão de cada classe. A partir daí, o classificador pode ser usada para perver o resultado sobre dados novos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import datasets\n",
    "\n",
    "#Criar uma instância do algoritmo de classificação KNN (K-nearest neighbor)\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "#Treinar o classificador\n",
    "knn.fit(x,y)\n",
    "\n",
    "#Calcular o valor previsto de acordo com o modelo\n",
    "yhat = knn.predict(x)\n",
    "\n",
    "#Checar o resultado do último exemplo\n",
    "print 'Valor previsto: ' + str (yhat [ -1]), ', valor real: ' + str (y [ -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar a Acurácia: **Número de Previsões Corretas / Total de Previsões**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A distribuição dos rótulos de predição é dada pelo seguinte gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.pie(np.c_[np.sum(np.where(y==1,1,0)),np.sum(np.where(y==-1,1,0))][0],\n",
    "        labels=['Financiado parcialmente','Financiado totalmente'],\n",
    "        colors=['g','r'],\n",
    "        shadow=False,\n",
    "        autopct ='%.2f' )\n",
    "plt.gcf().set_size_inches((6,6))\n",
    "plt.savefig(\"pie.png\",dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular a matriz de confusão:\n",
    "+ TP (verdadeiro positivo): o classificador prevê um exemplo como positivo, e ele realmente é positivo.\n",
    "+ FP (falso positivo): o classificador prevê um exemplo como positivo, mas ele é negativo.\n",
    "+ TN (verdadeiro negativo): o classificador prevê um exemplo como negativo, e ele realmente é negativo.\n",
    "+ FN (falso negativo): o classificador prevê um exemplo como negativo, mas ele é positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yhat = knn.predict(x)\n",
    "TP = np.sum(np.logical_and(yhat==-1,y==-1))\n",
    "TN = np.sum(np.logical_and(yhat==1,y==1))\n",
    "FP = np.sum(np.logical_and(yhat==-1,y==1))\n",
    "FN = np.sum(np.logical_and(yhat==1,y==-1))\n",
    "print 'TP: '+ str(TP), ', FP: '+ str(FP)\n",
    "print 'FN: '+ str(FN), ', TN: '+ str(TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(yhat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Treinamento do classificador com K = 1\n",
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(x,y)\n",
    "yhat=knn.predict(x)\n",
    "\n",
    "print \"Acurácia do classificador:\", metrics.accuracy_score(yhat, y)\n",
    "print \"Matriz de confusão: \\n\" + str(metrics.confusion_matrix(yhat, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até este ponto utilizamos dados de treinamento para \"avaliar\" o desempenho do classificador, mas esta é uma prática não recomendada. Vamos usar um subconjunto dos dados de treinamento para **testar** o desempenho do classificador.\n",
    "\n",
    "A avaliação do desempenho é uma etapa de **validação** do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dividindo o dataset em dois conjuntos de dados, se treinamento e de teste.\n",
    "import numpy as np\n",
    "perm = np.random.permutation(y.size)\n",
    "PRC = 0.7\n",
    "split_point = int(np.ceil(y.shape[0]*PRC))\n",
    "\n",
    "X_train = x[perm[:split_point].ravel(),:]\n",
    "y_train = y[perm[:split_point].ravel()]\n",
    "\n",
    "X_test = x[perm[split_point:].ravel(),:]\n",
    "y_test = y[perm[split_point:].ravel()]\n",
    "\n",
    "print 'Dados de entrada do treinamento: ' + str(X_train.shape), ' , resposta do treinamento: '+str(y_train.shape)\n",
    "print 'Dados de entrada do teste: ' + str(X_test.shape), ' , resposta do teste: '+str(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Treinar o classificador com os dados de treinamento\n",
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "#Visualizar o desempenho\n",
    "yhat=knn.predict(X_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "print \"\\nESTATÍSTICA DO TREINAMENTO:\"\n",
    "print \"Acurácia do classificador:\", metrics.accuracy_score(yhat, y_train)\n",
    "print \"Matriz de confusão: \\n\"+ str(metrics.confusion_matrix(y_train, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Analisar com os dados de teste\n",
    "yhat=knn.predict(X_test)\n",
    "print \"ESTATÍSTICAS DO TESTE:\"\n",
    "print \"Acurácia do classificador:\", metrics.accuracy_score(yhat, y_test)\n",
    "print \"Matriz de confusão: \\n\"+ str(metrics.confusion_matrix(yhat,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível automatizar esse processo, com as ferramentas fornecidas pelo pacote scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Divisão feita com os pacotes fornecidos pelo pacote sklearn:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn import metrics\n",
    "\n",
    "PRC = 0.3\n",
    "acc = np.zeros((10,))\n",
    "for i in xrange(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=PRC)\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(X_train,y_train)\n",
    "    yhat = knn.predict(X_test)\n",
    "    acc[i] = metrics.accuracy_score(yhat, y_test)\n",
    "acc.shape=(1,10)\n",
    "print \"Erro médio: \"+str(np.mean(acc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós podemos usar o processo de validação para a seleção do algoritmo de AM.\n",
    "\n",
    "Vamos analisar o desempenho de quatro classificadores diferentes sobre o mesmo conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "PRC = 0.1\n",
    "acc_r=np.zeros((10,4))\n",
    "for i in xrange(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=PRC)\n",
    "    nn1 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "    nn3 = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "    svc = svm.SVC()\n",
    "    dt = tree.DecisionTreeClassifier()\n",
    "    \n",
    "    nn1.fit(X_train,y_train)\n",
    "    nn3.fit(X_train,y_train)\n",
    "    svc.fit(X_train,y_train)\n",
    "    dt.fit(X_train,y_train)\n",
    "    \n",
    "    yhat_nn1=nn1.predict(X_test)\n",
    "    yhat_nn3=nn3.predict(X_test)\n",
    "    yhat_svc=svc.predict(X_test)\n",
    "    yhat_dt=dt.predict(X_test)\n",
    "    \n",
    "    acc_r[i][0] = metrics.accuracy_score(yhat_nn1, y_test)\n",
    "    acc_r[i][1] = metrics.accuracy_score(yhat_nn3, y_test)\n",
    "    acc_r[i][2] = metrics.accuracy_score(yhat_svc, y_test)\n",
    "    acc_r[i][3] = metrics.accuracy_score(yhat_dt, y_test)\n",
    "\n",
    "\n",
    "plt.boxplot(acc_r);\n",
    "for i in xrange(4):\n",
    "    xderiv = (i+1)*np.ones(acc_r[:,i].shape)+(np.random.rand(10,)-0.5)*0.1\n",
    "    plt.plot(xderiv,acc_r[:,i],'ro',alpha=0.3)\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels(['1-NN','3-NN','SVM','Decission Tree'])\n",
    "plt.ylabel('Acuracia')\n",
    "plt.savefig(\"plots/error_ms_1.png\",dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
