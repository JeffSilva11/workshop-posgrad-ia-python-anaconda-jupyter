{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 03 - Aprendizagem de Máquina (Parte II)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas de Aprendizagem\n",
    "\n",
    "Vamos relembrar os dois conceitos básicos definidos anteriormente. Falamos de **erro de treinamento** (ou erro dentro da amostra), que se refere ao erro medido em todas as amostras de dados observadas no conjunto de treinamento. Também falamos de **erro do teste** ou **erro de generalização**, como o erro esperado em dados novos.\n",
    "\n",
    "O objetivo da aprendizagem é minimizar o erro de generalização, encontrando um equilíbrio na divisão entre dados de treinamento e de teste.\n",
    "\n",
    "Vamos tentar entender o comportamento dos algoritmos de aprendizagem de máquina quando a quantidade de dados e a \"complexidade\" do método mudam. Isso é chamado de **curva da aprendizagem**. Vamos começar primeiro variando a quantidade de dados para uma complexidade fixa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um classificador e variar o número de exemplos fornecidos a ele para fins de treinamento, depois verificar o comportamento do treinamento e testar a precisão à medida que o número de exemplos aumenta. Neste caso específico, estaremos usando uma árvore de decisão com profundidade máxima fixa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "C=5 #profundidade da árvore de decisão\n",
    "MAXN=1000\n",
    "\n",
    "yhat_test=np.zeros((10,299,2))\n",
    "yhat_train=np.zeros((10,299,2))\n",
    "\n",
    "#Repetir dez vezes para visualizar curvas mais suaves\n",
    "for i in xrange(10):\n",
    "    X = np.concatenate([1.25*np.random.randn(MAXN,2),5+1.5*np.random.randn(MAXN,2)]) \n",
    "    X = np.concatenate([X,[8,5]+1.5*np.random.randn(MAXN,2)])\n",
    "    y = np.concatenate([np.ones((MAXN,1)),-np.ones((MAXN,1))])\n",
    "    y = np.concatenate([y,np.ones((MAXN,1))])\n",
    "    perm = np.random.permutation(y.size)\n",
    "    X = X[perm,:]\n",
    "    y = y[perm]\n",
    "\n",
    "    X_test = np.concatenate([1.25*np.random.randn(MAXN,2),5+1.5*np.random.randn(MAXN,2)]) \n",
    "    X_test = np.concatenate([X_test,[8,5]+1.5*np.random.randn(MAXN,2)])\n",
    "    y_test = np.concatenate([np.ones((MAXN,1)),-np.ones((MAXN,1))])\n",
    "    y_test = np.concatenate([y_test,np.ones((MAXN,1))])\n",
    "    j=0\n",
    "    for N in xrange(10,3000,10):\n",
    "        Xr=X[:N,:]\n",
    "        yr=y[:N]\n",
    "        \n",
    "        #Avaliar o modelo\n",
    "        clf = tree.DecisionTreeClassifier(min_samples_leaf=1, max_depth=C)\n",
    "        clf.fit(Xr,yr.ravel())\n",
    "        yhat_test[i,j,0] = 1. - metrics.accuracy_score(clf.predict(X_test), y_test.ravel())\n",
    "        yhat_train[i,j,0] = 1. - metrics.accuracy_score(clf.predict(Xr), yr.ravel())\n",
    "        j=j+1\n",
    "\n",
    "p1,=plt.plot(np.mean(yhat_test[:,:,0].T,axis=1),'pink')\n",
    "p2,=plt.plot(np.mean(yhat_train[:,:,0].T,axis=1),'c')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,5)\n",
    "plt.xlabel('Numero de exemplos x10')\n",
    "plt.ylabel('Taxa de erro')\n",
    "plt.legend([p1,p2],[\"Teste com C = 5\",\"Treinamento com C = 5\"])\n",
    "plt.savefig(\"plots/learning_curve_1.png\",dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba no gráfico acima que conforme o número de amostras de treinamento aumenta, ambos os erros tendem para o mesmo valor. Quando temos poucos dados de treinamento, o erro de treinamento é muito pequeno, mas o erro de teste é muito grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos repetir o processo com um classificador mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "C=1 #profundidade da árvore de decisão\n",
    "MAXN=1000\n",
    "\n",
    "#Repetir dez vezes para visualizar curvas mais suaves\n",
    "for i in xrange(10):\n",
    "    X = np.concatenate([1.25*np.random.randn(MAXN,2),5+1.5*np.random.randn(MAXN,2)]) \n",
    "    X = np.concatenate([X,[8,5]+1.5*np.random.randn(MAXN,2)])\n",
    "    y = np.concatenate([np.ones((MAXN,1)),-np.ones((MAXN,1))])\n",
    "    y = np.concatenate([y,np.ones((MAXN,1))])\n",
    "    perm = np.random.permutation(y.size)\n",
    "    X = X[perm,:]\n",
    "    y = y[perm]\n",
    "\n",
    "    X_test = np.concatenate([1.25*np.random.randn(MAXN,2),5+1.5*np.random.randn(MAXN,2)]) \n",
    "    X_test = np.concatenate([X_test,[8,5]+1.5*np.random.randn(MAXN,2)])\n",
    "    y_test = np.concatenate([np.ones((MAXN,1)),-np.ones((MAXN,1))])\n",
    "    y_test = np.concatenate([y_test,np.ones((MAXN,1))])\n",
    "    j=0\n",
    "    for N in xrange(10,3000,10):\n",
    "        Xr=X[:N,:]\n",
    "        yr=y[:N]\n",
    "        #Avaliar o modelo\n",
    "        clf = tree.DecisionTreeClassifier(min_samples_leaf=1, max_depth=C)\n",
    "        clf.fit(Xr,yr.ravel())\n",
    "        yhat_test[i,j,1] = 1. - metrics.accuracy_score(clf.predict(X_test), y_test.ravel())\n",
    "        yhat_train[i,j,1] = 1. - metrics.accuracy_score(clf.predict(Xr), yr.ravel())\n",
    "        j=j+1\n",
    "\n",
    "p3,=plt.plot(np.mean(yhat_test[:,:,1].T,axis=1),'r')\n",
    "p4,=plt.plot(np.mean(yhat_train[:,:,1].T,axis=1),'b')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,5)\n",
    "plt.xlabel('Numero de exemplos x10')\n",
    "plt.ylabel('Taxa de erro')\n",
    "plt.legend([p3,p4],[\"Teste com C = 1\",\"Treinamento com C = 1\"])\n",
    "plt.savefig(\"plots/learning_curve_2.png\",dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos juntar ambos os exemplos e analisar a diferença. É possível perceber o seguinte no gráfico a seguir:\n",
    "+ Com um baixo grau de complexidade, os erros de treinamento e teste convergem mais cedo / com menos dados.\n",
    "+ Além disso, com um baixo grau de complexidade, o erro de convergência é maior do que com o aumento da complexidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1,=plt.plot(np.mean(yhat_test[:,:,0].T,axis=1),color='pink')\n",
    "p2,=plt.plot(np.mean(yhat_train[:,:,0].T,axis=1),'c')\n",
    "p3,=plt.plot(np.mean(yhat_test[:,:,1].T,axis=1),'r')\n",
    "p4,=plt.plot(np.mean(yhat_train[:,:,1].T,axis=1),'b')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,5)\n",
    "plt.xlabel('Numero de exemplos x10')\n",
    "plt.ylabel('Taxa de erro')\n",
    "plt.legend([p1,p2,p3,p4],[\"Teste com C = 5\",\"Treinamento com C = 5\",\"Teste com C = 1\",\"Treinamento com C = 1\"])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,5)\n",
    "plt.savefig(\"plots/learning_curve_3.png\",dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar agora o que acontece quando fixamos a quantidade de dados e alteramos a complexidade da técnica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "MAXC=20\n",
    "N=1000\n",
    "NTEST=4000\n",
    "ITERS=3\n",
    "\n",
    "yhat_test=np.zeros((ITERS,MAXC,2))\n",
    "yhat_train=np.zeros((ITERS,MAXC,2))\n",
    "\n",
    "for i in xrange(ITERS):\n",
    "    X = np.concatenate([1.25*np.random.randn(N,2),5+1.5*np.random.randn(N,2)]) \n",
    "    X = np.concatenate([X,[8,5]+1.5*np.random.randn(N,2)])\n",
    "    y = np.concatenate([np.ones((N,1)),-np.ones((N,1))])\n",
    "    y = np.concatenate([y,np.ones((N,1))])\n",
    "    perm = np.random.permutation(y.size)\n",
    "    X = X[perm,:]\n",
    "    y = y[perm]\n",
    "\n",
    "    X_test = np.concatenate([1.25*np.random.randn(NTEST,2),5+1.5*np.random.randn(NTEST,2)]) \n",
    "    X_test = np.concatenate([X_test,[8,5]+1.5*np.random.randn(NTEST,2)])\n",
    "    y_test = np.concatenate([np.ones((NTEST,1)),-np.ones((NTEST,1))])\n",
    "    y_test = np.concatenate([y_test,np.ones((NTEST,1))])\n",
    "\n",
    "    j=0\n",
    "    for C in xrange(1,MAXC+1): #variação da complexidade (profundidade da árvore de decisão)\n",
    "        #Avaliar o modelo\n",
    "        clf = tree.DecisionTreeClassifier(min_samples_leaf=1, max_depth=C)\n",
    "        clf.fit(X,y.ravel())\n",
    "        yhat_test[i,j,0] = 1. - metrics.accuracy_score(clf.predict(X_test), y_test.ravel())\n",
    "        yhat_train[i,j,0] = 1. - metrics.accuracy_score(clf.predict(X), y.ravel())\n",
    "        j=j+1\n",
    "\n",
    "p1, = plt.plot(np.mean(yhat_test[:,:,0].T,axis=1),'r')\n",
    "p2, = plt.plot(np.mean(yhat_train[:,:,0].T,axis=1),'b')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,5)\n",
    "plt.xlabel('Complexidade')\n",
    "plt.ylabel('Taxa de erro')\n",
    "plt.legend([p1, p2], [\"Erro do teste\", \"Erro do treinamento\"])\n",
    "plt.savefig(\"plots/learning_curve_4.png\",dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe na figura acima que conforme a complexidade aumenta, o erro de treinamento é reduzido; mas acima de um certo nível de complexidade, o erro de teste passa a aumentar. Este efeito é chamado de **overfitting**. Existem algumas possibilidades para reduzir este problema. Os modelos geralmente são configurados por meio de alguns parâmetros. A seleção da complexidade geralmente é determinada por alguns desses parâmetros. Assim, temos a possibilidade de escolher o modelo ideal para nosso conjunto de dados. Uma boa solução para selecionar o modelo é escolher o valor dos parâmetros que produz o menor erro de teste estimado. Lembre-se de que isso pode ser feito usando validação cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar todos esses conceitos para compreender e selecionar a complexidade de um modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento, Validação e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de seleção dos melhores parâmetros de um modelo é chamado **Validação**. Isso introduz um novo conjunto em nosso esquema de simulação; agora precisamos dividir os dados que temos em três conjuntos: conjuntos de treinamento, validação e teste. Como vimos, o processo de avaliar o desempenho do classificador estimando o erro de generalização é chamado de teste. E o processo de seleção de um modelo usando a estimativa do erro de generalização é chamado de validação. Há uma diferença sutil, mas crítica entre os dois e temos que estar cientes disso ao lidar com problemas de classificação.\n",
    "\n",
    "+ Os dados de treinamento são usados para aprender a \"instância\" do modelo de uma classe de modelos.\n",
    "+ Os dados de teste são usados exclusivamente para avaliar o desempenho no final do processo e nunca serão usados no processo de aprendizagem.\n",
    "+ Os dados de validação são usados explicitamente para selecionar os parâmetros / modelos com o melhor desempenho de acordo com uma estimativa do erro de generalização. Esta é uma forma de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "ofname = open('files/dataset_small.pkl','rb') \n",
    "(X,y) = pickle.load(ofname)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Validação cruzada com a técnica K-fold, usando 10 partições\n",
    "kf=KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "      \n",
    "#Variação dos parâmetros: profundidade da árvore de decisão\n",
    "C=np.arange(2,20,)\n",
    "\n",
    "acc = np.zeros((10,18))\n",
    "i=0\n",
    "\n",
    "#Validação cruzada\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    j=0\n",
    "    for c in C:\n",
    "        dt = tree.DecisionTreeClassifier(min_samples_leaf=1, max_depth=c)\n",
    "        dt.fit(X_train,y_train)\n",
    "        yhat = dt.predict(X_val)\n",
    "        acc[i][j] = metrics.accuracy_score(yhat, y_val)\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    \n",
    "plt.boxplot(acc);\n",
    "for i in xrange(18):\n",
    "    xderiv = (i+1)*np.ones(acc[:,i].shape)+(np.random.rand(10,)-0.5)*0.1\n",
    "    plt.plot(xderiv,acc[:,i],'ro',alpha=0.3)\n",
    "\n",
    "print 'Acurácia média: ' + str(np.mean(acc,axis = 0))\n",
    "print 'Índice do modelo selecionado: ' + str(np.argmax(np.mean(acc,axis = 0)))\n",
    "print 'Complexidade: ' + str(C[np.argmax(np.mean(acc,axis = 0))])\n",
    "plt.ylim((0.7,1.))\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,5)\n",
    "plt.xlabel('Complexidade')\n",
    "plt.ylabel('Acuracia')\n",
    "plt.savefig(\"plots/model_selection.png\",dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver na figura acima, a melhor acurácia média é obtida pelo quinto modelo, cuja profundidade máxima é 6. Embora possamos verificar que a melhor precisão é com um valor de complexidade de 6, não podemos dizer nada sobre o valor que ela alcançará. Para ter uma estimativa desse valor, precisamos executar o modelo em um novo conjunto de dados diferente, tanto no treinamento quanto na seleção do modelo. Vamos fazer isso a seguir, estaremos considerando uma divisão simples de teste e treinamento, e em seguida, executaremos a validação cruzada para a seleção do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
